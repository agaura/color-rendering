<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;

            margin: 0;
            overflow: hidden;
            background-color: #AAAAAA;
            background-attachment: fixed !important;
        }
    </style>
    <style>
        body {
            font-family: Monospace;
            margin: 0px;
            overflow: hidden;
        }
    </style>
</head>

<body>
    <div id='timer'></div>

    <script id="vertShader" type="shader">
        varying vec2 vUv;
        void main() {
            vUv = vec2( uv.x, 1.0-uv.y );
            gl_Position = projectionMatrix *
                          modelViewMatrix * vec4(position, 1.0 );
        }
        </script>

    <script id="gaussFragShader" type="shader">
            precision highp float;
            uniform sampler2D image;
            uniform vec2 resolution;
            uniform float sigma;
            uniform int size;
            uniform bool dim;
            
            varying vec2 vUv;
            
            float gauss(int x) {
                float coef = 1.0 / (sqrt(2.0 * 3.14159) * sigma);
                float funcx = exp( - pow(float(x), 2.0) / (2.0 * pow(sigma, 2.0)));
                return coef * funcx;
            }
            
            void main(void) {
                            vec2 cellSize = 1.0 / resolution.xy;
                            vec2 uv = vUv.xy;
                            vec3 temp = vec3(0.0);
                            for (int i = - size; i <= size; i++) {temp += 
                                texture2D(image, uv + vec2(float(dim)*float(i)*cellSize.x, float(!dim)*float(i)*cellSize.y)).rgb*gauss(i);}
                            gl_FragColor = vec4(temp, 1.0);
                    }
            </script>

    <script id="KNNFragShader" type="shader">
            precision highp float;
            uniform sampler2D image;
            uniform vec2 resolution;
            uniform int size;
            uniform float percent;
            uniform float tau;
            uniform float alpha;
            
            varying vec2 vUv;
            
            int findx(int point) {
                int dim = size * 2 + 1;
                return (point / dim) - size;
            }
            
            int findy(int point) {
                int dim = size * 2 + 1;
                return (point % dim) - size;
            }
            
            vec3 KNNmedian(int inds[121], float vals[121]) {
            
                vec2 cellSize = 1.0 / resolution.xy;
                vec2 uv = vUv.xy;
            
                // insertion sort 
            
                float neigh = pow(2.0 * float(size) + 1.0, 2.0);
            
                float key = 0.0;
                int xKey = 0;
                int j = 0;
                for (int i = 1; i < int(neigh); i++) {
                        key = vals[i];
                        xKey = inds[i];
                        j = i - 1;
             
                        while (j >= 0 && vals[j] > key) {
                                vals[j + 1] = vals[j];
                                inds[j + 1] = inds[j];
                                j = j - 1;
                            }
                        
                        vals[j + 1] = key;
                        inds[j + 1] = xKey;
                        }
            
                // find median
            
                vec3 color = vec3(0.0);
            
                int num = int(floor(neigh * percent));
                if (num % 2 == 0) {
                    vec3 colora = texture2D(image, uv + vec2(float(findx(inds[(num - 2) / 2]))*cellSize.x, float(findy(inds[(num - 2) / 2]))*cellSize.y)).rgb;
                    vec3 colorb = texture2D(image, uv + vec2(float(findx(inds[num / 2]))*cellSize.x, float(findy(inds[num / 2]))*cellSize.y)).rgb;
                    color = (colora + colorb) / 2.0;
                }
                else {color = texture2D(image, uv + vec2(float(findx(inds[(num - 1) / 2]))*cellSize.x, float(findy(inds[(num - 1) / 2]))*cellSize.y)).rgb;}
                return color;
            }
            
            vec3 colorGrab(int i, int j) {return texture2D(image, vUv.xy + vec2(float(i) / resolution.x, float(j) / resolution.y)).rgb;}
            
            void main(void) {
                            vec2 cellSize = 1.0 / resolution.xy;
                            vec2 uv = vUv.xy;
            
                            vec3 temp = vec3(0.0);
            
                            float dist[121];
                            int x[121];
            
                            int index = 0;
                            for (int i = - size; i <= size; i++)
                                for (int j = - size; j <= size; j++) {
                                    x[index] = index;
                                    dist[index] = length(texture2D(image, uv).rgb - texture2D(image, uv + vec2(float(i)*cellSize.x, float(j)*cellSize.y)).rgb);
                                    index += 1;
                                }
            
                            gl_FragColor = vec4(KNNmedian(x, dist), 1.0);
        
                    }
            </script>

    <script id="arithFragShader" type="shader">
                precision highp float;
                uniform sampler2D image;
                uniform sampler2D image2;
                uniform float scale;
                uniform float offset;
                uniform int mode;
                
                varying vec2 vUv;
                void main(void) {
                                vec2 uv = vUv.xy;
                                vec4 textureValue = vec4(0.0,0.0,0.0,0.0);
                
                                if (mode == 0) {textureValue = vec4(texture2D(image, uv) + texture2D(image2, uv)) * scale + offset;}
                                else if (mode == 1) {textureValue = vec4(texture2D(image, uv) - texture2D(image2, uv)) * scale + offset;}
                                else if (mode == 2) {textureValue = vec4(texture2D(image, uv) * texture2D(image2, uv)) * scale + offset;}
                                else if (mode == 3) {textureValue = vec4(texture2D(image, uv) / texture2D(image2, uv)) * scale + offset;}
                
                                textureValue[3] = 1.0; // make sure the alpha isn't changed
                                gl_FragColor = textureValue;
                        }
                </script>

    <script id="scaleVertShader" type="shader">
                    varying vec2 vUv;
                    uniform float scale;
                    void main() {
                        vUv = vec2( uv.x, 1.0-uv.y );
                        gl_Position = projectionMatrix *
                                      modelViewMatrix * vec4(position * scale, 1.0 );
                    }
                    </script>

    <script id="scaleFragShader" type="shader">
                    precision highp float;
                    uniform sampler2D image;
                    uniform vec2 resolution;
                    
                    varying vec2 vUv;
                    void main(void) {
                                    vec2 cellSize = 1.0 / resolution.xy;
                                    vec2 uv = vUv.xy;
                    
                                    // find horizontal and vertical distance from the bottom-left cell
                    
                                    float leftDist = uv.x / cellSize.x - floor(uv.x / cellSize.x);   // distance to left edge
                                    leftDist += ceil( - (leftDist - 0.5)) - 0.5;					 // adjust distance to center of left/current cell if it's on the left/right side of its own cell
                                    float bottomDist = uv.y / cellSize.y - floor(uv.y / cellSize.y); // distance to bottom edge
                                    bottomDist += ceil( - (bottomDist - 0.5)) - 0.5;				 // adjust distance to center of bottom/current cell if it's on the bottom/top side of its own cell
                    
                                    // find the four pixels being used for interpolation
                    
                                    float horShift = - ceil(leftDist - 0.5) * cellSize.x;			 // shift to left cell
                                    float vertShift = - ceil(bottomDist - 0.5) * cellSize.y;		 // shift to bottom cell
                    
                                    vec4 botLeft = texture2D(image, uv + vec2(horShift, vertShift));
                                    vec4 topLeft = texture2D(image, uv + vec2(horShift, vertShift + cellSize.y));
                                    vec4 botRight = texture2D(image, uv + vec2(horShift + cellSize.x, vertShift));
                                    vec4 topRight = texture2D(image, uv + vec2(horShift + cellSize.x, vertShift + cellSize.y));
                    
                                    // creating and multiplying matrices l * M * r for the interpolation
                    
                                    vec2 l = vec2(1.0 - leftDist, leftDist);
                                    vec2 r = vec2(1.0 - bottomDist, bottomDist);
                    
                                    float texX = dot(l, r * mat2(botLeft.x, topLeft.x, botRight.x, topRight.x));
                                    float texY = dot(l, r * mat2(botLeft.y, topLeft.y, botRight.y, topRight.y));
                                    float texZ = dot(l, r * mat2(botLeft.z, topLeft.z, botRight.z, topRight.z));
                                    float texW = dot(l, r * mat2(botLeft.w, topLeft.w, botRight.w, topRight.w));
                    
                                    gl_FragColor = vec4(texX, texY, texZ, texW);
                            }
                    </script>

    <script type="text/javascript" src="http://lo-th.github.io/uil/build/uil.js"></script>
    <script type="module">

        import * as THREE from 'https://cdn.skypack.dev/three@0.125.0';
        import { OrbitControls } from 'https://cdn.skypack.dev/three@0.125.0/examples/jsm/controls/OrbitControls.js';
        import { GUI } from 'https://cdn.skypack.dev/three@0.125.0/examples/jsm/libs/dat.gui.module.js';

        function IVimageProcessing(height, width, imageProcessingMaterial) {
            this.height = height;
            this.width = width;

            //3 rtt setup
            this.scene = new THREE.Scene();
            this.orthoCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 1 / Math.pow(2, 53), 1);

            //4 create a target texture
            var options = {
                minFilter: THREE.NearestFilter,
                magFilter: THREE.NearestFilter,
                format: THREE.RGBAFormat,
                //            type:THREE.FloatType
                type: THREE.UnsignedByteType
            };
            this.rtt = new THREE.WebGLRenderTarget(width, height, options);

            var geom = new THREE.BufferGeometry();
            geom.addAttribute('position', new THREE.BufferAttribute(new Float32Array([-1, -1, 0, 1, -1, 0, 1, 1, 0, -1, -1, 0, 1, 1, 0, -1, 1, 0]), 3));
            geom.addAttribute('uv', new THREE.BufferAttribute(new Float32Array([0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0]), 2));
            this.scene.add(new THREE.Mesh(geom, imageProcessingMaterial));
        }

        function IVprocess(imageProcessing, renderer) {
            renderer.setRenderTarget(imageProcessing.rtt);
            renderer.render(imageProcessing.scene, imageProcessing.orthoCamera);
            renderer.setRenderTarget(null);
        };

        var camera, controls, scene, renderer, container;
        var plane, plane2;

        // VIDEO AND THE ASSOCIATED TEXTURE
        var srcTexture;
        var h, w;
        var texType;

        var imageProcessing, imageProcessingMaterial,
            imageProcessing2, imageProcessingMaterial2,
            imageProcessing3, imageProcessingMaterial3,
            imageProcessing4, imageProcessingMaterial4,
            scalingMaterial;

        // GUI
        var gui, ui;
        var timing;
        var clock = new THREE.Clock();
        var ptime;
        var selectorVal;

        init();
        animate();

        function init() {
            timing = false;

            container = document.createElement('div');
            document.body.appendChild(container);

            scene = new THREE.Scene();

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.autoClear = false;
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.shadowMap.enabled = false;

            container.appendChild(renderer.domElement);

            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.001, 10);
            camera.position.z = 0.7;
            controls = new OrbitControls(camera, renderer.domElement);
            controls.minDistance = 0.005;
            controls.maxDistance = 1.0;
            controls.enableRotate = true;
            controls.addEventListener('change', render);
            controls.update();

            var thisurl = window.location.href;
            var strarray = thisurl.split("=");
            texType = strarray[strarray.length - 1];

            if (texType == 'webcam') {
                selectorVal = 'Webcam';

                if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                    const constraints = { video: { width: 1280, height: 720, facingMode: 'user' } };
                    navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                        var video = document.createElement('video');
                        video.srcObject = stream;
                        video.play();

                        video.onloadeddata = function () {
                            srcTexture = new THREE.VideoTexture(video);

                            h = video.videoHeight;
                            w = video.videoWidth;

                            initTex();

                        };

                    })
                }

            }

            else if (texType == 'image') {
                selectorVal = 'Image';

                var loader = new THREE.TextureLoader();
                loader.load("grenouille.jpg", function (tex) {
                    h = tex.image.height;
                    w = tex.image.width;

                    srcTexture = tex;

                    initTex();

                });

            }

            else {
                selectorVal = 'Video';

                var video = document.createElement('video');
                video.src = 'small.mp4';
                video.load();
                video.muted = true;
                video.loop = true;

                video.onloadeddata = function () {
                    srcTexture = new THREE.VideoTexture(video);

                    h = video.videoHeight;
                    w = video.videoWidth;

                    initTex();

                    video.play();
                };
            }

            window.addEventListener('resize', onWindowResize, false);
        }

        function initTex() {
            srcTexture.minFilter = THREE.NearestFilter;
            srcTexture.magFilter = THREE.NearestFilter;
            srcTexture.generateMipmaps = false;
            srcTexture.format = THREE.RGBFormat;

            imageProcessingMaterial = new THREE.ShaderMaterial({
                uniforms: {
                    image: { type: 't', value: srcTexture },
                    resolution: { type: '2f', value: new THREE.Vector2(w, h) },
                    sigma: { type: 'f', value: 1.0 },
                    size: { type: 'i', value: 2 },
                    dim: { type: 'b', value: false }
                },
                vertexShader: document.
                    getElementById('vertShader').text,
                fragmentShader: document.
                    getElementById('gaussFragShader').text,
            });

            imageProcessing = new IVimageProcessing(h, w, imageProcessingMaterial);

            imageProcessingMaterial2 = new THREE.ShaderMaterial({
                uniforms: {
                    image: { type: 't', value: imageProcessing.rtt.texture },
                    resolution: { type: '2f', value: new THREE.Vector2(w, h) },
                    sigma: { type: 'f', value: 1.0 },
                    size: { type: 'i', value: 2 },
                    dim: { type: 'b', value: true }
                },
                vertexShader: document.
                    getElementById('vertShader').text,
                fragmentShader: document.
                    getElementById('gaussFragShader').text,
            });

            imageProcessing2 = new IVimageProcessing(h, w, imageProcessingMaterial2);

            imageProcessingMaterial3 = new THREE.ShaderMaterial({
                uniforms: {
                    scale: { type: 'f', value: 1.0 },
                    image: { type: 't', value: srcTexture },
                    resolution: { type: '2f', value: new THREE.Vector2(w, h) },
                    percent: { type: 'f', value: 1.0 },
                    size: { type: 'i', value: 2 },
                    tau: { type: 'f', value: 1.0 },
                    alpha: { type: 'f', value: 1.0 }
                },
                vertexShader: document.
                    getElementById('vertShader').text,
                fragmentShader: document.
                    getElementById('KNNFragShader').text,
            });

            imageProcessing3 = new IVimageProcessing(h, w, imageProcessingMaterial3);

            imageProcessingMaterial4 = new THREE.ShaderMaterial({
                uniforms: {
                    scale: { type: 'f', value: 1.0 },
                    image: { type: 't', value: imageProcessing2.rtt.texture },
                    image2: { type: "t", value: imageProcessing3.rtt.texture },
                    offset: { type: 'f', value: 0.0 },
                    mode: { type: 'i', value: 1 },
                },
                vertexShader: document.
                    getElementById('vertShader').text,
                fragmentShader: document.
                    getElementById('arithFragShader').text,
            });

            imageProcessing4 = new IVimageProcessing(h, w, imageProcessingMaterial4);

            scalingMaterial = new THREE.ShaderMaterial({
                uniforms: {
                    scale: { type: 'f', value: 1.0 },
                    image: { type: 't', value: imageProcessing4.rtt.texture },
                    resolution: { type: '2f', value: new THREE.Vector2(w, h) }
                },
                vertexShader: document.
                    getElementById('scaleVertShader').text,
                fragmentShader: document.
                    getElementById('scaleFragShader').text,
            });

            var scale = 1.0;
            var factor = h / w;
            var planeGeometry = new THREE.PlaneGeometry(scale, scale * factor, w, h);
            plane = new THREE.Mesh(planeGeometry, scalingMaterial);
            plane.material.side = THREE.DoubleSide;
            plane.position.z = -0.8;
            plane.rotation.z = Math.PI;
            if (texType != 'webcam') { plane.rotation.y = Math.PI; }
            scene.add(plane);

            var geometry2 = new THREE.PlaneGeometry(1, h / w);
            var material2 = new THREE.MeshBasicMaterial({ map: srcTexture, side: THREE.DoubleSide });
            plane2 = new THREE.Mesh(geometry2, material2);
            plane2.position.z = -1;
            plane2.position.y = -0.5;
            plane2.receiveShadow = false;
            plane2.castShadow = false;
            if (texType == 'webcam') { plane2.rotation.y = Math.PI; }
            scene.add(plane2);

            var timer = document.getElementById('timer');

            ui = new UIL.Gui({ w: 350, h: 20, close: false });
            ui.add('bool', { name: 'Processing', h: 20, value: false }).onChange(function () {
                if (timing) { timer.innerHTML = ''; }
                timing = !timing;
            });
            ui.add('slide', { name: 'Gauss Kernel Size', min: 0, max: 100, precision: 0, value: 2 }).onChange(function (p) { imageProcessingMaterial.uniforms.size.value = p; imageProcessingMaterial2.uniforms.size.value = p; });
            ui.add('slide', { name: 'Sigma', min: 0, max: 50, precision: 2, value: 1 }).onChange(function (p) { imageProcessingMaterial.uniforms.sigma.value = p; imageProcessingMaterial2.uniforms.sigma.value = p; });
            ui.add('slide', { name: 'KNN Kernel Size', min: 0, max: 5, precision: 0, value: 2 }).onChange(function (p) { imageProcessingMaterial3.uniforms.size.value = p; });
            ui.add('slide', { name: 'Percent', min: 0, max: 1, precision: 2, value: 1 }).onChange(function (p) { imageProcessingMaterial3.uniforms.percent.value = p; });
            ui.add('slide', { name: 'Scale', min: 0, max: 10, precision: 2, value: 1 }).onChange(function (p) { imageProcessingMaterial3.uniforms.scale.value = p; });
            ui.add('slide', { name: 'Offset', min: -1, max: 1, precision: 2, value: 0 }).onChange(function (p) { imageProcessingMaterial4.uniforms.offset.value = p; });
            ui.add('selector', { name: 'Mode', value: '-', values: ['+', '-', '*', '/'] }).onChange(function (p) {
                if (p == '+') { imageProcessingMaterial4.uniforms.mode.value = 0; }
                else if (p == '-') { imageProcessingMaterial4.uniforms.mode.value = 1; }
                else if (p == '*') { imageProcessingMaterial4.uniforms.mode.value = 2; }
                else { imageProcessingMaterial4.uniforms.mode.value = 3; }
            });
            ui.add('slide', { name: 'Scale', min: 0, max: 10, precision: 2, value: 1 }).onChange(function (p) { scalingMaterial.uniforms.scale.value = p; });
            ui.add('selector', { name: 'Source', value: selectorVal, values: ['Image', 'Video', 'Webcam'] }).onChange(function (p) {
                var currenturl = window.location.href.split("test.html")[0];
                if (p == 'Image') { window.location.replace(currenturl + "test.html?sourceimage=image"); }
                else if (p == 'Video') { window.location.replace(currenturl + "test.html?sourceimage=video"); }
                else { window.location.replace(currenturl + "test.html?sourceimage=webcam"); }
            });
        }

        function render() {
            renderer.clear();

            if (typeof imageProcessing !== 'undefined') IVprocess(imageProcessing, renderer);
            if (typeof imageProcessing2 !== 'undefined') IVprocess(imageProcessing2, renderer);
            if (typeof imageProcessing3 !== 'undefined') IVprocess(imageProcessing3, renderer);
            if (typeof imageProcessing4 !== 'undefined') IVprocess(imageProcessing4, renderer);

            renderer.render(scene, camera);

        }

        function animate() {
            if (timing) { timer.innerHTML = (100 * clock.getDelta()).toFixed(5) + " ms"; }
            requestAnimationFrame(animate);
            controls.update();
            render();
        }

        function onWindowResize() {
            camera.aspect = (window.innerWidth / window.innerHeight);
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            render();
        }

    </script>
</body>

</html>